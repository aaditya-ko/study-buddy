# ğŸ“š StudyBuddy Live

**Paper-first AI study companion with emotion-aware tutoring and natural voice**

## ğŸ¯ What It Does

StudyBuddy Live watches you work on physical paper/notebooks through your camera while providing proactive, emotionally-aware tutoring through voice conversation. It's like having a study buddy sitting across from you.

### Key Features

- ğŸ“„ **PDF Analysis** - Understands your assignment context
- ğŸ¯ **Problem Highlighting** - Drag to select what you're working on
- ğŸ“¸ **Ambient Emotion Detection** - Monitors frustration, confusion, breakthroughs
- ğŸ“ **Show Work Analysis** - AI sees your written work and provides Socratic guidance
- ğŸ—£ï¸ **Natural Voice Conversation** - Deepgram TTS for human-like AI voice
- ğŸ‰ **Breakthrough Celebrations** - Confetti when you solve it!
- ğŸ’¾ **Session History** - Review past study sessions

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
npm install
```

### 2. Set Up API Keys

Create `.env.local` in the project root:

```bash
# REQUIRED: Claude AI (chat + vision)
ANTHROPIC_API_KEY=sk-ant-xxxxx

# REQUIRED: Deepgram TTS (natural voice)
DEEPGRAM_API_KEY=xxxxx

# OPTIONAL: Supabase (session persistence)
NEXT_PUBLIC_SUPABASE_URL=https://xxxxx.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=eyJxxxxx
```

**Get API Keys:**
- Anthropic: [console.anthropic.com](https://console.anthropic.com/)
- Deepgram: [console.deepgram.com](https://console.deepgram.com/) (Free $200 credits!)
- Supabase: [supabase.com/dashboard](https://supabase.com/dashboard)

### 3. Run Development Server

```bash
npm run dev
```

Open [http://localhost:3000](http://localhost:3000)

## ğŸ“– How to Use

1. **Upload PDF** - Drag your assignment/problem set
2. **Set Support Level** - Slider: Minimal / Standard / High
3. **Highlight Problem** - Click "Highlight" and drag box over current problem
4. **Start Listening** - Enable microphone for voice conversation
5. **Study Naturally** - AI proactively checks in, adapts to your emotions
6. **Show Work** - Click button to get feedback on written work (3s countdown)

## ğŸ—ï¸ Tech Stack

- **Frontend**: Next.js 14 (App Router), React, TypeScript, TailwindCSS
- **AI**: Claude Sonnet 4 (Anthropic) for chat + vision
- **Voice**: Deepgram Aura-2 TTS + Web Speech API (STT)
- **PDF**: react-pdf with custom highlight tool
- **Camera**: getUserMedia + Canvas API
- **Database**: Supabase (PostgreSQL + Storage)
- **Design**: Anthropic-inspired (warm ivory, indigo accents)

## ğŸ“ Project Structure

```
src/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ chat/route.ts           # Claude conversation with emotion awareness
â”‚   â”‚   â”œâ”€â”€ pdf/analyze/route.ts    # PDF context + highlighted problem analysis
â”‚   â”‚   â”œâ”€â”€ tts/speak/route.ts      # Deepgram TTS proxy
â”‚   â”‚   â””â”€â”€ vision/
â”‚   â”‚       â”œâ”€â”€ ambient/route.ts    # Emotion detection (low-res)
â”‚   â”‚       â””â”€â”€ showwork/route.ts   # Work analysis (high-res)
â”‚   â”œâ”€â”€ page.tsx                    # Landing: Upload + intensity slider
â”‚   â”œâ”€â”€ session/[id]/page.tsx       # Main session: PDF + camera + voice
â”‚   â””â”€â”€ sessions/page.tsx           # Past sessions history
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ IntensitySlider.tsx         # Support level selector
â”‚   â””â”€â”€ UploadCard.tsx              # PDF upload UI
â””â”€â”€ lib/
    â”œâ”€â”€ anthropic.ts                # Claude client
    â””â”€â”€ supabase.ts                 # Database client
```

## ğŸ¨ Design Language

Inspired by Anthropic's Claude interface:
- **Warm ivory background** (`#fcfaf7`) - cozy, paper-like
- **Indigo accent** (`#3e63dd`) - calm, trustworthy
- **Generous spacing & shadows** - depth and hierarchy
- **Rounded corners** (16px) - soft, approachable
- **Heroicons** - professional, non-generic icons

## ğŸ“Š How It Works

### Two-Mode Camera System

**Ambient Mode** (every 6-15 seconds):
- Low-res capture (512Ã—384)
- Emotion detection only
- Monitors: focused, frustrated, confused, breakthrough, neutral
- Saved to database for session history

**Show Work Mode** (button press):
- High-res capture (1024Ã—768)
- Analyzes written work + diagrams
- Cross-references with highlighted problem
- Returns: praise, observations, guiding questions

### Proactive AI Behavior

Instead of waiting for you to ask:
- **Check-ins every 2-4 min** (based on intensity)
- **Emotion-aware responses** (adapts if frustrated)
- **Celebrates breakthroughs** with confetti ğŸ‰
- **Natural conversation memory** (full context maintained)

### Voice System

- **Speech-to-Text**: Web Speech API (browser native)
- **Text-to-Speech**: Deepgram Aura-2 (`aura-asteria-en` - warm, friendly)
- **Queue system**: Prevents overlapping responses
- **User interrupt**: Speaking auto-cancels AI voice
- **Fallback**: Browser TTS if Deepgram unavailable

## ğŸ“š Documentation

- [DEEPGRAM_SETUP.md](./DEEPGRAM_SETUP.md) - TTS integration guide
- [SUPABASE_PERSISTENCE.md](./SUPABASE_PERSISTENCE.md) - Database setup
- [EMOTION_DETECTION.md](./EMOTION_DETECTION.md) - How emotion detection works

## ğŸ› Troubleshooting

### Voice sounds robotic
- Check `DEEPGRAM_API_KEY` is set in `.env.local`
- Restart dev server after adding key
- Look for `[Voice] âœ… Deepgram audio received` in console

### Camera not working
- Grant camera permissions in browser
- Use Chrome/Edge (best WebRTC support)
- Check for `[Camera]` logs in console

### PDF not analyzing
- Verify `ANTHROPIC_API_KEY` is set
- Check network tab for API errors
- Look for `[PDF-ANALYZE]` logs

## ğŸ“ Hackathon Notes

**Innovation Points:**
- âœ… Paper-first paradigm (camera watches natural study posture)
- âœ… Proactive AI (initiates check-ins, doesn't wait)
- âœ… Dual-mode vision (emotion vs. work analysis)
- âœ… Emotional awareness (adapts tutoring style)

**Design Points:**
- âœ… Anthropic-inspired warmth
- âœ… Smooth interactions (hover animations, countdown)
- âœ… Real-time feedback (emotion badges, confetti)
- âœ… Professional polish (Deepgram TTS)

## ğŸ“„ License

Built for hackathon demo - all rights reserved

